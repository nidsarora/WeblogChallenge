{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace import sarimax\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from pandas import Series\n",
    "from statsmodels.tsa.arima_model import ARIMA \n",
    "os.chdir(\"C:/Users/arora/Documents/spark-python\")  \n",
    "os.environ['SPARK_HOME'] = 'C:/Users/arora/spark-2.3.3-bin-hadoop2.7'\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def time_delta(y,x): \n",
    "    from datetime import datetime\n",
    "    end = datetime.strptime(y, '%Y-%m-%dT%H:%M:%S.%fZ')  \n",
    "    start = datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "    delta = (end-start).total_seconds()\n",
    "    return delta\n",
    "\n",
    "\n",
    "\n",
    "# Create a variable for our root path\n",
    "SPARK_HOME = os.environ['SPARK_HOME']\n",
    "\n",
    "#Add the following paths to the system path. \n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"pyspark.zip\"))\n",
    "sys.path.insert(0,os.path.join(SPARK_HOME,\"python\",\"lib\",\"py4j-0.10.7-src.zip\"))\n",
    "\n",
    "pathToTextFile = r'''C:\\Users\\arora\\WeblogChallenge\\data\\2015_07_22_mktplace_shop_web_log_sample.log.gz'''  \n",
    "\n",
    "df = pd.read_csv(pathToTextFile, sep=\" \", names=[\"timestamp_str\",\"elb_name\",\"client_ip\",\"back_end_ip\",\"request_processing_time\",\"backend_processing_time\",\\\n",
    "           \"response_processing_time\",\"elb_status_code\",\"backend_status_code\",\"received_bytes\",\"sent_bytes\",\\\n",
    "           \"request\",\"user_agent\",\"ssl_cipher\",\"ssl_protocol\"])\n",
    "df['user_agent'] = df['user_agent'].astype(str)\n",
    "df['url'] = df['request'].astype(str).str.split().str[1]\n",
    "df['IP']=df['client_ip'].astype(str).str.split().str[0]\n",
    "df.drop('request', axis=1, inplace=True)\n",
    "df.drop('client_ip', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import TimestampType,IntegerType\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "SpSession = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Weblog Challenge\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.cores.max\",\"2\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"C:/Users/arora/WeblogChallenge/spark-warehouse\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# #Create a Spark Session\n",
    "# SpSession = SparkSession \\\n",
    "#     .builder \\\n",
    "#     .master(\"local[2]\") \\\n",
    "#     .appName(\"Nidhi\") \\\n",
    "#     .getOrCreate()\n",
    "    \n",
    "#Get the Spark Context from Spark Session    \n",
    "sc = SpSession.sparkContext\n",
    "\n",
    "\n",
    "logDataFrame = SpSession.createDataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[timestamp_str: string, elb_name: string, client_ip: string, back_end_ip: string, request_processing_time: double, backend_processing_time: double, response_processing_time: double, elb_status_code: bigint, backend_status_code: bigint, received_bytes: bigint, sent_bytes: bigint, request: string, user_agent: string, ssl_cipher: string, ssl_protocol: string, url: string, IP: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func =  udf (lambda x: datetime.strptime(x, '%Y-%m-%dT%H:%M:%S.%fZ'), TimestampType())\n",
    "\n",
    "func2 =  udf (lambda x: x.replace(microsecond=0), TimestampType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDataFrameWithIP = logDataFrame.withColumn('time_stamp', func(col('timestamp_str')))\n",
    "\n",
    "logDataFrameWithIPNoMicroSecs = logDataFrameWithIP.withColumn('time_stamp_without_microsecs', func2(col('time_stamp')))\n",
    "logDataFrameWithIPNoMicroSecs.take(1)\n",
    "logDataFrameWithIPNoMicroSecs.createOrReplaceTempView(\"df_time_stamp_without_microsecs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logDataFrameIPTimeStamp = logDataFrameWithIP.withColumn('time_stamp_previous',\n",
    "                        lag(logDataFrameWithIP.time_stamp,1)\n",
    "                                 .over(Window.partitionBy(\"IP\").orderBy(\"time_stamp\")))\n",
    "\n",
    "logDataFrameIPTimeStamp.select('IP').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDataFrameIPTimeStamp = logDataFrameIPTimeStamp.withColumn(\n",
    "    \"time_diff_in_secs\", \n",
    "    unix_timestamp(\"time_stamp\") - unix_timestamp(\"time_stamp_previous\")\n",
    ")\n",
    "\n",
    "logDataFrameIPTimeStamp.select('*').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDataFrameIPTimeStamp.createOrReplaceTempView(\"log_session\")\n",
    "SpSession.sql(\"select IP,time_diff_in_secs from log_session where time_diff_in_secs>900 order by IP, time_stamp,user_agent \").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDataFrameSession = logDataFrameIPTimeStamp.select(F.when(logDataFrameIPTimeStamp.time_diff_in_secs > 900, lit(1)).otherwise(lit(0)).alias(\"new_session\"))\n",
    "logDataFrameSession.select('*').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDataFrameSession = logDataFrameIPTimeStamp.withColumn('new_session',F.when(((logDataFrameIPTimeStamp.time_diff_in_secs > 900) | (logDataFrameIPTimeStamp.time_diff_in_secs.isNull())), lit(1)).otherwise(lit(0)))\n",
    "logDataFrameSession.createOrReplaceTempView(\"log_new_session\")\n",
    "SpSession.sql(\"select IP,time_diff_in_secs,new_session from log_new_session\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDataFrameSessionId = SpSession.sql(\"select *,(SUM(new_session) OVER (PARTITION BY IP ORDER BY IP,time_stamp)) as session_id from log_new_session\")\n",
    "logDataFrameSessionId.createOrReplaceTempView(\"log_new_session_id\")\n",
    "SpSession.sql(\"select IP,new_session,session_id,time_stamp,time_diff_in_secs,time_stamp_previous from log_new_session_id order by IP,time_stamp\").show(5)\n",
    "#Q1 i.e the sessions are represented by logDataFrameSessionId, Every IP has its own session ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpSession.sql(\"select * from log_new_session_id where IP is null\").count()\n",
    "#So, null IPs are there\n",
    "\n",
    "###################################Q2###############################################\n",
    "\n",
    "logDataFrameSessionTime = SpSession.sql(\"select IP,session_id,sum(time_diff_in_secs) as session_time from log_new_session_id group by IP,session_id order by IP,session_id\")\n",
    "logDataFrameSessionTime.show()\n",
    "logDataFrameSessionTime.createOrReplaceTempView(\"log_session_time\")\n",
    "SpSession.sql(\"select Avg(session_time) as avg_session_time from log_session_time\").show()\n",
    "#Average session time is 2625.0743308697874 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################Q3###############################################\n",
    "\n",
    "SpSession.sql(\"select distinct IP,session_id, request from log_new_session_id\").take(1)\n",
    "logUniqueVisits = SpSession.sql(\"select IP,session_id,count(*) as unique_url_count from ( select distinct IP,session_id, url from log_new_session_id )group by IP,session_id order by IP,session_id\")\n",
    "logUniqueVisits.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################Q4###############################################\n",
    "\n",
    "SpSession.sql(\"select IP,session_time from log_session_time  where session_time is not null order by session_time desc\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Data prep\n",
    "\n",
    "SpSession.sql(\"select time_stamp_without_microsecs from df_time_stamp_without_microsecs order by time_stamp_without_microsecs asc\").take(10)\n",
    "requestsPrepDf = SpSession.sql(\"select time_stamp_without_microsecs, count(*) as requests_per_sec from df_time_stamp_without_microsecs group by time_stamp_without_microsecs order by time_stamp_without_microsecs\")\n",
    "SpSession.sql(\"select min(time_stamp_without_microsecs),max(time_stamp_without_microsecs) from df_time_stamp_without_microsecs\").show(5)\n",
    "requestsPrepDf.createOrReplaceTempView(\"df_requests_prep\")\n",
    "SpSession.sql(\"select time_stamp_without_microsecs,requests_per_sec from df_requests_prep\").count()\n",
    "requestsPredDf = SpSession.sql(\"select requests_per_sec from df_requests_prep\")\n",
    "df_requests_pd = requestsPredDf.toPandas()\n",
    "\n",
    "acf = plot_acf(df_requests_pd[180:240])\n",
    "acf.savefig(r'''C:\\Users\\arora\\WeblogChallenge\\images\\acf.png''')\n",
    "acf = plot_pacf(df_requests_pd[180:240])\n",
    "acf.savefig(r'''C:\\Users\\arora\\WeblogChallenge\\images\\pacf.png''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check stationarity\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "diff = df_requests_pd.values.mean()\n",
    "diff_d1 = difference(df_requests_pd.values,1).mean()#value of d=1 gives stationarity and minimum mean\n",
    "diff_d2 = difference(df_requests_pd.values,2).mean()\n",
    "\n",
    "df_requests_pd =df_requests_pd['requests_per_sec']\n",
    "train = df_requests_pd[2289:4089]\n",
    "test = df_requests_pd[-180:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history=[x for x in train]\n",
    "#\n",
    "#model = ARIMA(history,order=(5, 1, 4))\n",
    "#model_fit = model.fit(disp=0)\n",
    "#output = model_fit.aic\n",
    "#\n",
    "#\n",
    "#model = sarimax.SARIMAX(history,order=(1, 1, 1), seasonal_order=(1, 1, 1,60),enforce_stationarity=False, enforce_invertibility=False)\n",
    "#model_fit = model.fit(disp=0)\n",
    "#current_aic = model_fit.aic\n",
    "#               \n",
    "#final_aic = float('Inf')\n",
    "#for p in range(0,7):\n",
    "#    for q in range(0,7): \n",
    "#               print(\"p,q\",p,q)\n",
    "#               model = ARIMA(history,order=(p, 1, q))\n",
    "#               model_fit = model.fit(disp=0)\n",
    "#               current_aic = model_fit.aic\n",
    "#               print(current_aic)\n",
    "#               if(current_aic<final_aic):\n",
    "#                   final_aic = current_aic\n",
    "#                   final_p = p\n",
    "#                   final_q = q\n",
    "#                   print(\"final p q are\",final_p,final_q)\n",
    "#                   \n",
    "#for p in range(0,5):\n",
    "#    for q in range(0,5):\n",
    "#       for  P in range(0,5):\n",
    "#           for Q in range(0,5): \n",
    "#               print(\"p,q,P,Q\",p,q,P,Q)\n",
    "#               model = sarimax.SARIMAX(history,order=(p, 1, q), seasonal_order=(P, 1, Q,60),enforce_stationarity=False, enforce_invertibility=False)\n",
    "#               model_fit = model.fit(disp=0)\n",
    "#               current_aic = model_fit.aic\n",
    "#               print(current_aic)\n",
    "#               if(current_aic<final_aic):\n",
    "#                   final_aic = current_aic\n",
    "#                   final_p = p\n",
    "#                   final_q = q\n",
    "#                   final_P = P\n",
    "#                   final_Q = Q\n",
    "#                   print(\"final p q P Q are\",final_p,final_q,final_P, final_Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
